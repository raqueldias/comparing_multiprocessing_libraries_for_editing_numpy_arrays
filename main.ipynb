{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Raquel Dias\n",
    "The goal of this notebook is to benchmark multiple parallel processing libraries\n",
    "The target task consists of editing values in chunks of a shared numpy array.\n",
    "A certain proportion of the values in the array will be set to zero after picking their indexes randomly.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parallel processing libraries\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import threading, queue\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "alt_signal_only=False\n",
    "do_numpy_masking=True\n",
    "par_mask_proc=8\n",
    "s=6000 #simulating a batch of s observations (samples)\n",
    "v=6500 #number of variables (variants)\n",
    "a=2 #values per variable (alleles)\n",
    "n_batches=100\n",
    "my_input = np.ones((s,v*a))\n",
    "my_input = my_input.reshape((s,int(v),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_runtime(f,*args,nreps=10):\n",
    "    #print(args)\n",
    "    my_avg=0\n",
    "    for i in range(nreps):\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "\n",
    "        result = f(*args)\n",
    "    \n",
    "        stop = timeit.default_timer()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        print(\"rep\",i,\":\",(stop - start))\n",
    "\n",
    "        my_avg += (stop - start) / nreps\n",
    "        \n",
    "    print('Average time: ', my_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_data_per_sample_parallel(mydata, par_mask_method, mask_rate=0.9, categorical=\"False\"):\n",
    "\n",
    "    nmask = int(round(len(mydata[0])*mask_rate))\n",
    "    my_mask=[0,0]\n",
    "\n",
    "    if(categorical==\"True\"):\n",
    "        my_mask=-1\n",
    "    elif(alt_signal_only==True):\n",
    "        my_mask=0\n",
    "\n",
    "    def chunks(l, n):\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "\n",
    "    if(do_numpy_masking==True):\n",
    "        m=len(mydata[0])\n",
    "        s=len(mydata)\n",
    "        arr=np.arange(m)\n",
    "        # random matrix of indexes\n",
    "        if(par_mask_method==\"joblib\"):\n",
    "            \n",
    "            def mask_worker(data,nmask,replace=False):\n",
    "                inds=np.random.choice(arr,size=nmask, replace=False)\n",
    "                data[np.arange(len(data))[:, None], inds] = [0,0]\n",
    "                return data\n",
    "            \n",
    "            result=joblib.Parallel(n_jobs=par_mask_proc)(joblib.delayed(mask_worker)(i,nmask) for i in chunks(mydata,par_mask_proc))\n",
    "            mydata=np.array(result)\n",
    "                       \n",
    "        elif(par_mask_method==\"thread\"):\n",
    "         \n",
    "            proc = []\n",
    "            q = queue.Queue()\n",
    "            \n",
    "            def mask_worker(data,q):\n",
    "                inds = np.random.choice(arr,size=nmask, replace=False)\n",
    "                data[np.arange(len(data))[:, None], inds] = [0,0]\n",
    "                q.put(data)\n",
    "            \n",
    "            for i in chunks(mydata,par_mask_proc):\n",
    "                p = threading.Thread(target=mask_worker, args=(i,q))\n",
    "                p.Daemon = True\n",
    "                proc.append(p)\n",
    "                               \n",
    "            for i in chunks(proc,par_mask_proc):\n",
    "                for j in i:\n",
    "                    j.start()\n",
    "                for j in i:\n",
    "                    j.join()\n",
    "            \n",
    "            mydata = [q.get() for i in proc]\n",
    "            \n",
    "            mydata = np.array(mydata)\n",
    "            return mydata\n",
    "\n",
    "           \n",
    "        elif(par_mask_method==\"threadpool\" or par_mask_method==\"pool\"):\n",
    "                       \n",
    "            def mask_worker(data):\n",
    "                inds=np.random.choice(arr,size=nmask, replace=False)\n",
    "                data[np.arange(len(data))[:, None], inds] = [0,0]\n",
    "                return data\n",
    "            \n",
    "            pool = multiprocessing.pool.ThreadPool(par_mask_proc)\n",
    "            result = pool.map(mask_worker,chunks(mydata,par_mask_proc))\n",
    "            pool.close()\n",
    "            pool.join()    \n",
    "            result = [val for sublist in result for val in sublist]\n",
    "            mydata = np.array(result)\n",
    "            \n",
    "        elif(par_mask_method==\"ray\"):\n",
    "            #a little slower if you restart ray every time\n",
    "            #ray.shutdown()\n",
    "            #ray.init()\n",
    "            @ray.remote\n",
    "            def mask_worker(data):\n",
    "                inds=np.random.choice(arr,size=nmask, replace=False)\n",
    "                #fails if we try to overwrite, solution bellow\n",
    "                data.setflags(write=1)\n",
    "                data[np.arange(len(data))[:, None], inds] = [0,0]\n",
    "\n",
    "            futures = [mask_worker.remote(i) for i in chunks(mydata,par_mask_proc)]\n",
    "            result = ray.get(futures)\n",
    "            result = np.array(result)\n",
    "            mydata = result\n",
    "            #ray.shutdown()\n",
    "            \n",
    "        else:\n",
    "            inds=[np.random.choice(arr,size=nmask,replace=False) for i in range(s)]\n",
    "            #slower\n",
    "            #inds=np.stack([np.random.choice(np.arange(m),size=nmask,replace=False) for i in range(s)])\n",
    "            mydata[np.arange(s)[:, None], inds] = my_mask\n",
    "    else:\n",
    "        #REAAAAAAALLY SLOOOOOOW, not using this anymore\n",
    "        j = 0\n",
    "        while j < len(mydata):\n",
    "            #redefines which variants will be masked for every new sample\n",
    "            maskindex = random.sample(range(0, len(mydata[0]-1)), nmask) \n",
    "            for i in maskindex:\n",
    "                mydata[j][i]=my_mask\n",
    "            j=j+1\n",
    "\n",
    "    return mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0 : 2.8467207923531532\n",
      "rep 1 : 2.446762025821954\n",
      "rep 2 : 2.5559678939171135\n",
      "Average time:  2.616483570697407\n"
     ]
    }
   ],
   "source": [
    "measure_runtime(mask_data_per_sample_parallel,np.copy(my_input),\"serial\",0.95,nreps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0 : 0.8282273770309985\n",
      "rep 1 : 0.9477627142332494\n",
      "rep 2 : 0.9965687529183924\n",
      "Average time:  0.9241862813942134\n"
     ]
    }
   ],
   "source": [
    "measure_runtime(mask_data_per_sample_parallel,np.copy(my_input),\"pool\",0.95,nreps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0 : 5.727488715667278\n",
      "rep 1 : 3.9238162506371737\n",
      "rep 2 : 3.524286929052323\n",
      "Average time:  4.391863965118925\n"
     ]
    }
   ],
   "source": [
    "measure_runtime(mask_data_per_sample_parallel,np.copy(my_input),\"joblib\",0.95,nreps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0 : 1.147389508318156\n",
      "rep 1 : 1.1911329659633338\n",
      "rep 2 : 1.2736856141127646\n",
      "Average time:  1.204069362798085\n"
     ]
    }
   ],
   "source": [
    "measure_runtime(mask_data_per_sample_parallel,np.copy(my_input),\"thread\",0.95,nreps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-06 10:17:02,525\tINFO resource_spec.py:205 -- Starting Ray with 12.84 GiB memory available for workers and up to 6.44 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0 : 5.236430027987808\n",
      "rep 1 : 1.3128844080492854\n",
      "rep 2 : 1.183456470258534\n",
      "Average time:  2.577590302098542\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "measure_runtime(mask_data_per_sample_parallel,my_input,\"ray\",0.95,nreps=3)\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores: 2 method: serial\n",
      "rep 0 : 5.582591149024665\n",
      "rep 1 : 5.368513234890997\n",
      "rep 2 : 5.133274368941784\n",
      "Average time:  5.361459584285815\n",
      "Number of cores: 2 method: pool\n",
      "rep 0 : 4.183285878971219\n",
      "rep 1 : 4.341285431757569\n",
      "rep 2 : 4.191703453660011\n",
      "Average time:  4.2387582547962666\n",
      "Number of cores: 2 method: thread\n",
      "rep 0 : 6.244843455962837\n",
      "rep 1 : 6.572435938287526\n",
      "rep 2 : 6.495041779708117\n",
      "Average time:  6.437440391319494\n",
      "Number of cores: 2 method: joblib\n",
      "rep 0 : 7.351932437624782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raqueld/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 1 : 8.524115597829223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-06 10:18:42,245\tINFO resource_spec.py:205 -- Starting Ray with 15.28 GiB memory available for workers and up to 7.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 2 : 8.000370273832232\n",
      "Average time:  7.958806103095412\n",
      "Number of cores: 2 method: ray\n",
      "rep 0 : 9.343328353017569\n",
      "rep 1 : 4.904000014066696\n",
      "rep 2 : 5.023518930654973\n",
      "Average time:  6.423615765913079\n",
      "Number of cores: 4 method: serial\n",
      "rep 0 : 5.877057794947177\n",
      "rep 1 : 5.304797041229904\n",
      "rep 2 : 5.4754237732850015\n",
      "Average time:  5.5524262031540275\n",
      "Number of cores: 4 method: pool\n",
      "rep 0 : 2.3429697430692613\n",
      "rep 1 : 2.6157713211141527\n",
      "rep 2 : 2.6968920500949025\n",
      "Average time:  2.5518777047594385\n",
      "Number of cores: 4 method: thread\n",
      "rep 0 : 3.769723561126739\n",
      "rep 1 : 3.8617144702002406\n",
      "rep 2 : 3.9173536538146436\n",
      "Average time:  3.8495972283805404\n",
      "Number of cores: 4 method: joblib\n",
      "rep 0 : 7.125276986975223\n",
      "rep 1 : 6.331410346087068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-06 10:20:18,244\tINFO resource_spec.py:205 -- Starting Ray with 15.28 GiB memory available for workers and up to 7.66 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 2 : 6.952824603766203\n",
      "Average time:  6.803170645609498\n",
      "Number of cores: 4 method: ray\n",
      "rep 0 : 6.995519456919283\n",
      "rep 1 : 3.3189884601160884\n",
      "rep 2 : 3.2063463921658695\n",
      "Average time:  4.5069514364004135\n",
      "Number of cores: 8 method: serial\n",
      "rep 0 : 5.607817193958908\n",
      "rep 1 : 5.2389279701747\n",
      "rep 2 : 5.16688754176721\n",
      "Average time:  5.337877568633607\n",
      "Number of cores: 8 method: pool\n",
      "rep 0 : 1.7400501789525151\n",
      "rep 1 : 1.8826302350498736\n",
      "rep 2 : 1.8865611739456654\n",
      "Average time:  1.8364138626493514\n",
      "Number of cores: 8 method: thread\n",
      "rep 0 : 2.3902946012094617\n",
      "rep 1 : 2.6317544551566243\n",
      "rep 2 : 2.384450905956328\n",
      "Average time:  2.468833320774138\n",
      "Number of cores: 8 method: joblib\n",
      "rep 0 : 6.312227194663137\n",
      "rep 1 : 6.5751835480332375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-06 10:21:39,450\tINFO resource_spec.py:205 -- Starting Ray with 13.82 GiB memory available for workers and up to 6.91 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 2 : 5.233146513812244\n",
      "Average time:  6.040185752169539\n",
      "Number of cores: 8 method: ray\n",
      "rep 0 : 6.158026240766048\n",
      "rep 1 : 2.614896550308913\n",
      "rep 2 : 2.567860417999327\n",
      "Average time:  3.7802610696914294\n"
     ]
    }
   ],
   "source": [
    "s=12000 #simulating a larger batch of s observations (samples)\n",
    "v=6500 #number of variables (variants)\n",
    "a=2 #values per variable (alleles)\n",
    "n_batches=100\n",
    "my_input = np.ones((s,v*a))\n",
    "my_input = my_input.reshape((s,int(v),a))\n",
    "\n",
    "for i in [2,4,8]:\n",
    "    global par_mask_proc\n",
    "    par_mask_proc = i\n",
    "    for j in [\"serial\",\"pool\",\"thread\",\"joblib\",\"ray\"]:\n",
    "        print(\"Number of cores:\", i, \"method:\", j)\n",
    "        if(j==\"ray\"):\n",
    "            ray.init()\n",
    "            measure_runtime(mask_data_per_sample_parallel,my_input,j,0.95,nreps=3)\n",
    "            ray.shutdown()\n",
    "        else:\n",
    "            measure_runtime(mask_data_per_sample_parallel,my_input,j,0.95,nreps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
